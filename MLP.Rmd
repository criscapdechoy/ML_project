---
author: "Cristina Capdevila"
---
```{r echo=FALSE, message=FALSE, warning=FALSE}
library(MASS)
library(nnet)


nutrition <- c(
  "fat_100g",
  "carbohydrates_100g",
  "sugars_100g",
  "proteins_100g",
  "salt_100g",
  "fiber_100g"
)

#remove factor and responsive vble
mydataset <- read.csv("final_data.csv")
```

As our last model we have used an artifficial neural network to predict the nutrition grade of the products of our DataSet (OpenFoodFacts). As before, we use the nutritional values as inputs of our models so as to predict the nutrition grade ($nutriscore_grade) First, we take a sample of the 1% of the original dataset for computational reasons, but still having a dataset of about 4000 instances.Then, we split the dataset into learning and test sets, selecting randomly 2/3 and 1/3 of the data. 

```{r}
set.seed(1876)

N <- nrow(mydataset)
sample_index = sample(1:N, N*0.01)
N <- N*0.01
mydataset <- mydataset[sample_index,]
mydataset <- mydataset[c(nutrition,'nutriscore_grade')]

learn <- sample(1:N, round(2*N/3))  # random indices for the learning set

nlearn <- length(learn)
ntest <- N - nlearn
```

Before implementing the NN we standardize the input dataset and factorize the nutrition_grade attribute.

```{r}
mydataset$nutriscore_grade <- factor(mydataset$nutriscore_grade)
mydataset[nutrition] <- apply(mydataset[nutrition],2,scale)

```

We use the `nnet` library to compute the neural network. 

To have a baseline reference and the first results, we fit a MLP without hidden neurons, i.e. a linear logistic model.

```{r}
model.nnet0 <- multinom(nutriscore_grade ~., data = mydataset, subset=learn, maxit=500)
```

The model is printing the value of fitting criterion plus weight decay term in each iteration when trying to converge without arriving to the maxit number of iterations. When the model converges it means that this value has been stabilized and tend to a concrete value when the number of iterations tend to infinity.

In order to compute train and test performance metrics on a model, we create the following utility function:

```{r}
errors <- function (model)
{
  options(digits=4)
  p1 <- as.factor(predict (model, type="class"))
  t1 <- table(p1,mydataset$nutriscore_grade[learn])
  cat ("Train = ", 100*(1-sum(diag(t1))/nlearn),"%\n")
  p2 <- as.factor(predict (model, newdata=mydataset[-learn,], type="class"))
  t2 <- table(p2,mydataset$nutriscore_grade[-learn])
  cat ("Test =  ", 100*(1-sum(diag(t2))/ntest),"%\n")
}
```
So the training error and test errors:

```{r}
errors (model.nnet0)
```


We now fit an MLP with just 5 hidden neurons and no regularization:

```{r}
model.nnet <- nnet(nutriscore_grade ~., data = mydataset, subset=learn, size=5, maxit=500)
```


Take your time to understand the output
```{r}
model.nnet 
```

As we expected 65 weigths mean: 6(input layers) x 5(hidden layers) + 5(input layers) x 5(hidden layers) + 5 bias (hidden layers) x 5 bias (output layers). 
```{r}
model.nnet$value
```


Fitted values for the training data  (first 10):
```{r}
model.nnet$fitted.values[1:10,]
```


Residuals (first 10):
```{r}
model.nnet$residuals[1:10,]
```


Now look at the 29 weights:

```{r}
model.nnet$wts
```



```{r}
summary(model.nnet)
```

We need regularization so we add decay.

```{r}
model.nnet <- nnet(nutriscore_grade ~., data = mydataset, subset=learn, size=5, maxit=200, decay=0.5)
```


Notice the big difference
```{r}
summary(model.nnet)
```


Now, let's compute the errors
```{r}
errors (model.nnet)
```

As expected the error in test set has dropped significally and it means that the decay can help the MLP.

To calibrate now the MLP and find a good values for the size (num of hidden layers) and the decay value (regularization) we performing 10x10 cross-validation to select the best combination of `size` and `decay`.

We use `caret` package to do so.

```{r}
library(caret)
```

To find the best network structure we are going to follow the next strategy: first we find which number of hidden layers fits best to the network to optimize the accuracy of the prediction, without regularization. Then, when we get the best amount we fix the decay value by analysing the results if we change it.

So we start by fixing the different sizes, numb of hidden layers in the nn we want to test:
```{r}
(sizes <- 2*seq(1,10,by=1))
```


Specify 10x10 CV structure:
```{r}
trc <- trainControl (method="repeatedcv", number=10, repeats=10)
```

Perform cross-validation and train final model with best parameters:
```{r}
model.10x10CV <- train (nutriscore_grade ~., data = mydataset, subset=learn, 
                        method='nnet', maxit = 500, trace = FALSE,
                        tuneGrid = expand.grid(.size=sizes,.decay=0), trControl=trc)
```


We can inspect the full results
```{r}
model.10x10CV$results
```

And the best model found:
```{r}
model.10x10CV$bestTune
```

Now we fix the values we want to test for the decay parameter, after fixing the number of hidden layers.
```{r}
(decays <- 10^seq(-2, 0, by=0.2))
```


Now optimize regularization parameter `decay` with  set to fixed 12 units (the best find, till here):
```{r}
model.10x10CV <- train (nutriscore_grade ~., data = mydataset, subset=learn, method='nnet', 
                        maxit = 500, trace = FALSE,
                        tuneGrid = expand.grid(.size=12,.decay=decays), trControl=trc)

```


We can inspect the full results
```{r}
model.10x10CV$results
```


and the best model found
```{r}
model.10x10CV$bestTune
```

We proceed to predict the test set with the final model structure we find out.

```{r}
p2 <- as.factor(predict (model.10x10CV, newdata=mydataset[-learn,], type="raw"))
t2 <- table(pred=p2,truth=mydataset$nutriscore_grade[-learn])
(error_rate.test <- 100*(1-sum(diag(t2))/ntest))
```

We get `r round(error_rate.test, digits=1)`% test error after all.

Finally we compute the confusion matrix.

```{r}

tt <- confusionMatrix(p2,mydataset$nutriscore_grade[-learn], mode="prec_recall")

print(tt$table)
print(tt$overall)

```

And we print the precision, recall and f-measure by class:

```{r}
tt$byClass
```


