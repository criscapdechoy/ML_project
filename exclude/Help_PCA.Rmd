---

author: "Cristina Capdevila"
---

```{r echo=FALSE, message=FALSE, warning=FALSE}
requiredPackages <- c("matrixStats", "ggplot2", "FactoMineR", "gridExtra", "ggpubr","DMwR", "plsdepot")
missingPackages <- requiredPackages[!(requiredPackages %in% installed.packages()[,"Package"])]
if(length(missingPackages)) install.packages(missingPackages)

library("matrixStats")
library("ggplot2")
library("gridExtra")
library("ggpubr")
library("DMwR")
library("plsdepot")
library("FactoMineR")

source("graphs.R")
source("useful.R")
options(width = 90)

```

In this assignment we are going to analyse the Russet dataset completed in the previous assignment. For that, we transform the dataset into a numerical matrix with the continuous variables (all except `demo`).

```{r}
data <- read.table("Russet_ineqdata_noNA.txt", sep="\t")
data$demo <- as.factor(data$demo)
X <- as.matrix(data[,-9])
n <- nrow(X); varnames <- colnames(X)
p <- ncol(X); indnames <- rownames(X)

n <- nrow(X); varnames <- colnames(X)
p <- ncol(X); indnames <- rownames(X)
```

# Custom PCA function



```{r}
custom_PCA <- function(X, weights, metric="eucl", graph=FALSE) {
    N <- diag(x=weights*1/sum(weights), nrow=n, ncol=n)
    G <- apply(N %*% X, 2, function(var) sum(var))
    Xcent <- sweep(X,2,G)
    if (metric == "eucl") {
      cov <- t(Xcent) %*% N %*% Xcent
      eigen <- eigen(cov); X <- Xcent
    } else {
      s <- apply(X, 2, function(var) sd(var[weights == 1]))
      S <- diag(x=1/s, nrow=p, ncol=p)
      Xstan <- Xcent %*% S
      cor <- t(Xstan) %*% N %*% Xstan
      eigen <- eigen(cor); X <- Xstan
    }
    
    eigenvalues <- eigen$values
    eigenvectors <- eigen$vectors
    kaiser.rule.lim <- mean(eigenvalues)
    sign.comp <- which(eigenvalues > kaiser.rule.lim)
    ret.info <- sum(eigenvalues[sign.comp])/sum(eigenvalues)
    print(paste0(length(sign.comp)," significant components (", round(ret.info*100,digits=2), "%)"))
    proj.ind <- X %*% eigenvectors[,sign.comp]
    proj.var <- sqrt(eigenvalues)*eigenvectors[,sign.comp]
    
    ggplot_screeplot <- function(eigenvalues, kaiser.rule.lim) {
  p <- length(eigenvalues)
  ggplot() + geom_hline(yintercept=kaiser.rule.lim, col="red") +
    geom_point(aes(1:p,eigenvalues), col="blue", size=2.8)  +
    geom_line(aes(1:p,eigenvalues), col="blue", size=0.8) + customtheme(tsize=12) + 
    ggtitle("Scree Plot") + xlab("Component Number") + ylab("Eigenvalue")
}

ggplot_ind_fm <- function(eigenvalues, proj.ind, colind, indnames) {
  d1.expl <- eigenvalues[1]/sum(eigenvalues)*100
  d2.expl <- eigenvalues[2]/sum(eigenvalues)*100
  xlab <- xlab(paste0("Dim 1 (", round(d1.expl, digits=2), "%)"))
  ylab <- ylab(paste0("Dim 2 (", round(d2.expl, digits=2), "%)"))
  ggplot() + geom_factormap_theme(xintercept=0, yintercept=0) + customtheme() +
    geom_point(aes(x=proj.ind[,1], y=proj.ind[,2], col=factor(data$demo)), size=2) +
    geom_text(aes(x=proj.ind[,1], y=proj.ind[,2], label=indnames), hjust=0, vjust=-0.5) +
    ggtitle("Individuals factor map (PCA)") + labs(colour="Demo") + xlab + ylab
}

ggplot_var_fm <- function(eigenvalues, proj.var, varnames) {
  d1.expl <- eigenvalues[1]/sum(eigenvalues)*100
  d2.expl <- eigenvalues[2]/sum(eigenvalues)*100
  xlab <- xlab(paste0("Dim 1 (", round(d1.expl, digits=2), "%)"))
  ylab <- ylab(paste0("Dim 2 (", round(d2.expl, digits=2), "%)"))
  ggplot() + geom_factormap_theme(xintercept=0, yintercept=0, circle=T) + customtheme() +
    geom_segment(aes(x=0, y=0, xend=proj.var[,1], yend=proj.var[,2]), arrow=arrow(length=unit(0.3,"cm"))) +
    geom_text(aes(x=proj.var[,1], y=proj.var[,2], label=varnames), hjust=0.5, vjust=-0.5) +
    ggtitle("Variables factor map (PCA)") + xlab + ylab + coord_fixed(ratio=1)
}
customtheme <- function(tsize=12) {
    return (theme_bw() + 
              theme(panel.grid.major=element_blank(), panel.grid.minor=element_blank(),
                    axis.text.x=element_text(size=tsize), axis.text.y=element_text(size=tsize),
                    axis.title.x=element_text(size=tsize), axis.title.y=element_text(size=tsize),
                    plot.title=element_text(size=tsize+2, face="bold", hjust=0.5),
                    legend.text=element_text(size=tsize)) +
              theme(legend.position="bottom"))
  }
  
  geom_circle <- function(center=c(0,0), rad=1, npoints=100){
    c <- annotate("path",
                  x=c(0)+rad*cos(seq(0,2*pi,length.out=100)),
                  y=c(0)+rad*sin(seq(0,2*pi,length.out=100)))
    return(c)
  }
  
  geom_factormap_theme <- function(xintercept, yintercept, circle=FALSE) {
    hline <- geom_hline(yintercept=0, linetype="dashed")
    vline <- geom_vline(xintercept=0, linetype="dashed")
    if (circle) {
      circle <- geom_circle(center=c(0,0), rad=1, npoints=100)
      return(c(hline, vline, circle))
    } else {
      return(c(hline, vline))
    }
  }

    
    if (graph) {
        g1 <- ggplot_screeplot(eigenvalues, kaiser.rule.lim)
        g2 <- ggplot_ind_fm(eigenvalues, proj.ind, factor(data$demo), indnames)
        g3 <- ggplot_var_fm(eigenvalues, proj.var, varnames)
        print(ggarrange(g1,g2,g3,ncol=3,widths=c(2,4,2.5)))
    }
    return(list(proj.ind=proj.ind, proj.var=proj.var, eigenvalues=eigenvalues,
                eigenvectors=eigenvectors))
}
```



```{r fig.width=12, fig.height=3.35, fig.align="center", message=FALSE, warning=FALSE}
weights <- rep(1, n)
pca.all.eucl <- custom_PCA(X, weights=weights, metric="eucl", graph=FALSE)
pca.all.norm.eucl <- custom_PCA(X, weights=weights, metric="norm.eucl", graph=TRUE)
```

In the first case the retained information is of `99.78%`. As it uses a centered matrix, the importance of the variables are influenced by their variance and also by the units of measurement where their where some may weight more than the others.

in the second case the retained information decreases to `73.05%`. It is a smaller value of representation, but all the variables weight the same as we use a standardized matrix where the units of measurement of all variables are normalized.

Now we will compare both results with the correlation of the variables with the significant components for both cases.


```{r message=FALSE, warning=FALSE}
cor(X, pca.all.eucl$proj.ind)
cor(X, pca.all.norm.eucl$proj.ind)
```



```{r fig.width=12, fig.height=3.35, fig.align="center", message=FALSE, warning=FALSE}
weights <- rep(1, n)
weights[which(rownames(X) == "Cuba")] <- 0
pca.nocuba.norm.eucl <- custom_PCA(X, weights=weights, metric="norm.eucl", graph=TRUE)
```



```{r}
cor(pca.all.norm.eucl$proj.ind, pca.nocuba.norm.eucl$proj.ind)
```

# FactoMineR PCA function


```{r fig.width=12, fig.height=3.35, fig.align="center", message=FALSE, warning=FALSE}
pca.fm <- FactoMineR::PCA(data, quali.sup=9, graph=FALSE)
pca.fm.eigenvalues <- pca.fm$eig[,c("eigenvalue")]
g1 <- ggplot_screeplot(pca.fm.eigenvalues, mean(pca.fm.eigenvalues))
g2 <- ggplot_ind_fm(pca.fm.eigenvalues, pca.fm$ind$coord, factor(data$demo), indnames)
g3 <- ggplot_var_fm(pca.fm.eigenvalues, pca.fm$var$coord, varnames)
ggarrange(g1,g2,g3,ncol=3,widths=c(2,4,2.5))
```

The best and worst represented individuals in the first factorial plane are Suisse and Libye respectively. Suisse has the higher contribution to the plane construction.

```{r}
best <- sort(apply(pca.fm$ind$cos2[,c(1,2)], 1, function(ind) sum(ind)), decreasing=TRUE)[1]
worst <- sort(apply(pca.fm$ind$cos2[,c(1,2)], 1, function(ind) sum(ind)), decreasing=FALSE)[1]
data.frame(ind=c(names(best), names(worst)), score=c(best, worst), row.names=c("Best represented", "Worst represented"))
```

And the three most influenced individuals in the first and the second components (because they have the highest contribution to the principal components variables) are:

```{r}
most.infl.dim1 <- sort(pca.fm$ind$contrib[,1], decreasing=TRUE)[1:3]
most.infl.dim2 <- sort(pca.fm$ind$contrib[,2], decreasing=TRUE)[1:3]
data.frame(indDim1=names(most.infl.dim1), scoreDim1=most.infl.dim1,
           indDim2=names(most.infl.dim2), scoreDim2=most.infl.dim2, row.names=c(1,2,3))
```


The best and worst represented variables in the first factorial plane (scored with the sum of the first and second dimension) are Gini (due to the highest concentration index) and Rent, respectively.

```{r}
best <- sort(apply(pca.fm$var$cos2[,c(1,2)], 1, function(var) sum(var)), decreasing=TRUE)[1]
worst <- sort(apply(pca.fm$var$cos2[,c(1,2)], 1, function(var) sum(var)), decreasing=FALSE)[1]
data.frame(var=c(names(best), names(worst)), score=c(best, worst), row.names=c("Best represented", "Worst represented"))
```

And the three most influenced variables in the first and the second dimension are:

```{r}
most.infl.dim1 <- sort(pca.fm$var$contrib[,1], decreasing=TRUE)[1:3]
most.infl.dim2 <- sort(pca.fm$var$contrib[,2], decreasing=TRUE)[1:3]
data.frame(indDim1=names(most.infl.dim1), scoreDim1=most.infl.dim1,
           indDim2=names(most.infl.dim2), scoreDim2=most.infl.dim2, row.names=c(1,2,3))
```



we want to know in which cases the modality rejects the null hypothesis. To test each case, we will use the Z-scores computed previously by FactoMineR to calculate a p-value. If that p-value is less than 0.05, we will reject the null hypothesis.

```{r, fig.show='hold'}
table <- pca.fm$quali.sup$v.test[,1:2]
for(i in 1:nrow(table)) {
    for(j in 1:ncol(table)) {
        Zscore <- pca.fm$quali.sup$v.test[,1:2][i,j]
        pvalue <- round(2*pnorm(-abs(Zscore)),digits=5)
        table[i,j] <- pvalue
    }
}
print(ifelse(table < 0.05, "Reject", "Accept"))
```

Now we see that demo1 in dimension 1 and demo 3 in dimension 1 and 2 has rejected the null hypothesis. Thus, we those modalities in those dimensions are significative, therefore they have some influence in the result.


```{r fig.width=10, fig.height=5, fig.align="center", message=FALSE, warning=FALSE}
X <- standardize_matrix(as.matrix(data[,-9]))
custom_nipals <- function(X, comps=2) {
    n <- nrow(X)
    p <- ncol(X)
    X.old <- X
    Psi <- matrix(0,nrow=n,ncol=comps)
    Phi <- matrix(0,nrow=p,ncol=comps)
    cor.xt <- matrix(0,nrow=p,ncol=comps)
    eigenvalues <- rep(0, comps)
    for(h in 1:comps) {
        Psi.h <- rowMeans(X.old)
        u.old <- rep(1, p)
            
        iter = 1
        repeat {
            u.h <- t(X.old) %*% Psi.h
            u.h = u.h / sqrt(sum(u.h^2))
            Psi.h <- X.old %*% u.h
            
            u.diff <- sum((u.h-u.old)^2)
            u.old <- u.h
            if (u.diff < 1e-06 || iter == 100) break
            iter = iter + 1
        }
        Phi[,h] <- u.h
        Psi[,h] <- Psi.h
        eigenvalues[h] = sum(Psi.h^2)/(n - 1)
        
        X.h = X.old - Psi.h %*% t(u.h)
        X.old = X.h
    }
    cor.xt <- cor(X,Psi)
    row.names(Psi) <- row.names(X)
    row.names(Phi) <- colnames(X)
    return(list(Psi=Psi, Phi=Phi, cor.xt=cor.xt, eigenvalues=eigenvalues))
}
```

```{r include=FALSE}
sign.comp <- 3
pca.nipals <- nipals(X, comps=sign.comp)
Psi <- pca.nipals$scores
Phi <- pca.nipals$loadings
biplot(Psi, Phi)
cor.xt <- pca.nipals$cor.xt
eigenvalues <- pca.nipals$values[,c("values")]
```



```{r fig.width=8, fig.height=4, fig.align="center", out.width='0.9\\linewidth', message=FALSE, warning=FALSE}
sign.comp <- 3
pca.custom.nipals <- custom_nipals(X, comps=3)
Psi <- pca.custom.nipals$Psi
Phi <- pca.custom.nipals$Phi
eigenvalues <- pca.custom.nipals$eigenvalues
ggplot_biplot(Psi, Phi, eigenvalues)
```



```{r fig.width=9, fig.height=3.5, fig.align="center", message=FALSE, warning=FALSE}
cor.xt <- pca.custom.nipals$cor.xt
pca.nipals.rot <- varimax(cor.xt)
Phi.rot <- pca.nipals.rot$loadings[1:p,]
Psi.rot <- X %*% solve(cor(X)) %*% Phi.rot
eigenvalues.rot <- diag(t(pca.nipals.rot$loadings) %*% pca.nipals.rot$loadings)

g1 <- ggplot_variables(Phi, eigenvalues, varnames)
g2 <- ggplot_variables(Phi.rot, eigenvalues.rot, varnames)
ggarrange(g1,g2,ncol=2)
```


Now we will compute a new PCA with `FactoMineR` and change the scores of individuals by our previous computed ones with the rotated components. Then, we can interpret them using `dimdesc` function.

```{r}
pca.fm <- PCA(X, graph=FALSE)
pca.fm$ind$coord[,1:sign.comp] <- Psi.rot
dimdesc(pca.fm, axes=1:sign.comp)
```


 
 
 

