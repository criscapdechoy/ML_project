---
  
  author: "Cristina Capdevila"
---
  
```{r echo=FALSE, message=FALSE, warning=FALSE}
requiredPackages <- c("matrixStats", "ggplot2", "FactoMineR", "gridExtra", "ggpubr","DMwR", "plsdepot")
missingPackages <- requiredPackages[!(requiredPackages %in% installed.packages()[,"Package"])]
if(length(missingPackages)) install.packages(missingPackages)

library("matrixStats")
library("ggplot2")
library("gridExtra")
library("ggpubr")
library("DMwR")
library("plsdepot")
library("FactoMineR")
library(chemometrics)

source("graphs.R")
source("useful.R")
rm(list = ls())
```
First, we define the columns we are interested with after a deep looking through the 1
```{r echo=FALSE, message=FALSE, warning=FALSE}
col_names <- c("countries_en",
               "additives_n",
               "pnns_groups_2",
               "nutriscore_score",
               "nutriscore_grade",
               "nova_group",
               "fat_100g",
               "carbohydrates_100g",
               "sugars_100g",
               "proteins_100g",
               "salt_100g",
               "fiber_100g"
)

nutrition <- c(
  "fat_100g",
  "carbohydrates_100g",
  "sugars_100g",
  "proteins_100g",
  "salt_100g",
  "fiber_100g"
)

files_list <-list.files("data",pattern=".csv")

unico = TRUE
if (!unico){
  # OLD 
  for (i in 1:length(files_list)) 
    {
  
    filename <- sprintf("data/%s",files_list[i])
    if (i==1){
      row_dataset <- read.csv2(filename,header=TRUE)
  
      colindex <-which(names(row_dataset) %in% col_names)
      row_dataset <-row_dataset[ , (names(row_dataset) %in% col_names)]
      col_names <- colnames(row_dataset)  
    } else {
      row_dataset <- read.csv2(filename,header=FALSE)
      row_dataset <-row_dataset[ , (names(row_dataset) %in% sprintf("V%d",colindex))]
      colnames(row_dataset) <- col_names
    }
    row_dataset[row_dataset==""]<-NA
    row_dataset[row_dataset=="unknown"]<-NA  
    row_dataset <- row_dataset[which(!is.na(row_dataset$nutriscore_score)),]
    row_dataset <- data.frame(row_dataset)
  
    if (i==1){
      mydataset <- row_dataset
    } else {
      mydataset <-rbind(mydataset,row_dataset)
    }
    
  }
  write.csv(mydataset,"complete_data.csv", row.names = FALSE)

} else {
  filename <- "input/clean_data.csv"
  row_dataset <- read.csv2(filename,header=TRUE)
  colindex <-which(names(row_dataset) %in% col_names)
  row_dataset <-row_dataset[ , (names(row_dataset) %in% col_names)]
  col_names <- colnames(row_dataset) 
  row_dataset[row_dataset==""]<-NA
  row_dataset[row_dataset=="unknown"]<-NA  
  row_dataset <- row_dataset[which(!is.na(row_dataset$nutriscore_score)),]
}

rm(i,files_list,filename,colindex)
```

Pre-processing done!

```{r echo=FALSE, message=FALSE, warning=FALSE}
mydataset <- data.frame(row_dataset)
mydataset[nutrition] <- apply(mydataset[nutrition],2,as.numeric)

errata <- !is.na(mydataset[nutrition])&(mydataset[nutrition]>1000)
mydataset[nutrition][errata] <- mydataset[nutrition][errata]/1000
mydataset[nutrition][is.na(mydataset[nutrition])] <- 0.0
mydataset[nutrition][mydataset[nutrition]>100] <- NA
rm(errata)
mydataset <- mydataset[which(rowMeans(!is.na(mydataset)) > 0.9),]


```


```{r echo=FALSE, message=FALSE, warning=FALSE}
## Take columns with more than 90% not NA 

X <- data.matrix(mydataset[c("nutriscore_score","nova_group",nutrition, "additives_n")])
n <- nrow(X); varnames <- colnames(X)
p <- ncol(X); indnames <- rownames(X)

boxplot(X)

```

```{r echo=FALSE, message=FALSE, warning=FALSE}
X_nonmiss <-X[which(rowMeans(!is.na(mydataset)) == 1),]
md = mahalanobis(X_nonmiss, center=apply(X_nonmiss, 2, mean), cov=var(X_nonmiss))
plot(density(md))
sort(md)

to_cut <- md[md>quantile(md, 0.975)]
to_cut <- row.names(as.matrix(to_cut))
X_nonoutlier <- X[-which(rownames(X) %in% to_cut),]
par(mfrow=c(1,1))
boxplot(X_nonoutlier)
```
```{r echo=FALSE, message=FALSE, warning=FALSE}
#IMPUTATION OF THE MISSING VALUES#
library("mice")

imp <- mice(X_nonoutlier, m = 1, nnet.MaxNWts = 2000)

X <- complete(imp)

summary(X)
rm(imp, row_dataset, X_nonmiss, X_nonoutlier, md)
```

```{r echo=FALSE, message=FALSE, warning=FALSE}
mydataset <- mydataset[-which(rownames(mydataset) %in% to_cut),]
mydataset[c("nutriscore_score","nova_group",nutrition, "additives_n")] <- X
write.csv(mydataset,"final_data.csv", row.names = FALSE)
```

```{r echo=FALSE, message=FALSE, warning=FALSE}
rm(mydataset,X)
mydataset <- read.csv("final_data.csv")
X <- mydataset[c("nutriscore_score","nova_group",nutrition, "additives_n")]
library(dplyr)
library (ggplot2)
library(FactoMineR)
library(factoextra)
library("matrixStats")
library("ggplot2")
library("gridExtra")
library("ggpubr")
library("DMwR")
library("plsdepot")
library("ggplot2")
library("ggpubr")
library ("cclust")
library("fpc")
#remove factor and responsive vble
X <- select(mydataset, 
                     -countries_en, 
                     -nutriscore_grade,
                     -pnns_groups_2,
                     -nutriscore_score)

head(final_data, n=9)
#PCA con funcion
res.pca <- prcomp(X, center = TRUE, scale. = TRUE)
summary(res.pca)

fviz_eig(res.pca)
# Eigenvalues
eig.val <- get_eigenvalue(res.pca)
eigenvalues <- eig.val$eigenvalue
kaiser.rule.lim <- mean(eigenvalues)
sign.comp <- which(eig.val$eigenvalue > kaiser.rule.lim) #we have 3 significant dimentions
print(sign.comp)

```

```{r echo=FALSE, message=FALSE, warning=FALSE}

ggplot_screeplot <- function(eigenvalues, sign.comp) {
  p <- length(eigenvalues)
  ggplot() + geom_hline(yintercept=sign.comp, col="red") +
    geom_point(aes(1:p,eigenvalues), col="blue", size=2.8)  +
    geom_line(aes(1:p,eigenvalues), col="blue", size=0.8) + 
    ggtitle("Scree Plot") + xlab("Component Number") + ylab("Eigenvalue")
}

g1 <- ggplot_screeplot(eigenvalues, sign.comp)

print(ggarrange(g1,ncol=3,widths=c(4,4,2.5)))

```

```{r echo=FALSE, message=FALSE, warning=FALSE}
# 4  Perform a hierarchical clustering with the significant factors, 
#decide the number of final classes to obtain and perform a consolidation operation of the clustering. 
res.ind <- get_pca_ind(res.pca)
Psi <- res.ind$coord[,sign.comp]
d <- dist(Psi, method="euclidean")
h.clust <- hclust(d, method="ward.D2")
rect.hclust(h.clust, k=4)
par(mfrow=c(1,2), mar=c(1,4,2,1))
plot(h.clust)
barplot(h.clust$height)
```

```{r echo=FALSE, message=FALSE, warning=FALSE}
#define number of classes
num.clust <- 4
ind.clusters <- cutree(h.clust, k=num.clust)
ind.clusters
table(ind.clusters) #classes and nr of elements for each

da = list(data=Psi, cluster=ind.clusters)
da
plot <-fviz_cluster(da,ggtheme = theme_minimal())
Psi.sup <- as.data.frame(pca.fm$ind.sup$coord)[,sign.comp]
clust.cent <- aggregate(as.data.frame(Psi),list(ind.clusters),mean)[,sign.comp+1]
clust.cent
Bss <- sum(rowSums(clust.cent^2)*as.numeric(table(ind.clusters)))
Tss <- sum(rowSums(Psi^2))
Ib <- 100*Bss/Tss
print(paste0("Inertia between clusters is ", round(Ib, digits=3), "%"))

# perform a consolidation operation of the clustering

k.means <- kmeans(Psi, centers=clust.cent)
Bss <- sum(rowSums(k.means$centers^2)*k.means$size) # = k.means$betweenss
Wss <- sum(k.means$withinss)                        # = k.means$tot.withinss
Ib <- 100*Bss/(Bss+Wss)
Ib
print(paste0("Inertia between clusters is ", round(Ib, digits=3), "%"))
ind.clusters <- k.means$cluster
ind.clusters

p1 <- fviz_cluster(k.means, data=Psi, k = num.clust, rect = TRUE, main = "After consilidation",ggtheme = theme_minimal())
p1

library(gridExtra)
grid.arrange(p1, plot)

#  5  Compute the Calinski-Harabassz index 

before_conso_index =  round(calinhara(da$data,da$cluster),digits=2)
before_conso_index
 
  
after_conso_index = round(calinhara(Psi,k.means$cluster),digits=2)
after_conso_index


#CH.3 <- clustIndex(Psi,int.clust, index="calinski")
CH_after= (Bss/Wss)
CH_after

CH_before=Bss/(Bss+Tss)
CH_before
#calculate it with and without kmeans


#the result is improved with calinski-Harabassz


# 6   Using the function catdes interpret and name the obtained clusters
#and represent them in the first factorial display. 
desc <- catdes(cbind(as.factor(k.means$cluster),data[-ind.sup,]),1)
desc$quanti

#  representation of clusters in first factorial plane

kmeans.cent <- k.means$centers
kmeans.cent

first_factorial <- fviz_cluster(k.means, data=Psi, k = num.clust, rect = TRUE, main = "Hclust ward",ggtheme = theme_minimal())
first_factorial

grid.arrange(p1, first_factorial)
#  assign cuba to a defined cluster

dist <- apply(clust.cent, 1, function(center) {
  sum((Psi.sup - center)^2)
}); print(dist)





```
