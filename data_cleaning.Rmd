---
  
  author: "Cristina Capdevila"
---
  
```{r echo=FALSE, message=FALSE, warning=FALSE}
requiredPackages <- c("matrixStats", "ggplot2", "FactoMineR", "gridExtra", "ggpubr","DMwR", "plsdepot")
missingPackages <- requiredPackages[!(requiredPackages %in% installed.packages()[,"Package"])]
if(length(missingPackages)) install.packages(missingPackages)

library("matrixStats")
library("ggplot2")
library("gridExtra")
library("ggpubr")
library("DMwR")
library("plsdepot")
library("FactoMineR")
library(chemometrics)

source("graphs.R")
source("useful.R")
rm(list = ls())
```
First, we define the columns we are interested with after a deep looking through the 1
```{r echo=FALSE, message=FALSE, warning=FALSE}
col_names <- c("countries_en",
               "additives_n",
               "pnns_groups_2",
               "nutriscore_score",
               "nutriscore_grade",
               "nova_group",
               "fat_100g",
               "carbohydrates_100g",
               "sugars_100g",
               "proteins_100g",
               "salt_100g",
               "fiber_100g"
)

nutrition <- c(
  "fat_100g",
  "carbohydrates_100g",
  "sugars_100g",
  "proteins_100g",
  "salt_100g",
  "fiber_100g"
)

files_list <-list.files("data",pattern=".csv")

unico = TRUE
if (!unico){
  # OLD 
  for (i in 1:length(files_list)) 
    {
  
    filename <- sprintf("data/%s",files_list[i])
    if (i==1){
      row_dataset <- read.csv2(filename,header=TRUE)
  
      colindex <-which(names(row_dataset) %in% col_names)
      row_dataset <-row_dataset[ , (names(row_dataset) %in% col_names)]
      col_names <- colnames(row_dataset)  
    } else {
      row_dataset <- read.csv2(filename,header=FALSE)
      row_dataset <-row_dataset[ , (names(row_dataset) %in% sprintf("V%d",colindex))]
      colnames(row_dataset) <- col_names
    }
    row_dataset[row_dataset==""]<-NA
    row_dataset[row_dataset=="unknown"]<-NA  
    row_dataset <- row_dataset[which(!is.na(row_dataset$nutriscore_score)),]
    row_dataset <- data.frame(row_dataset)
  
    if (i==1){
      mydataset <- row_dataset
    } else {
      mydataset <-rbind(mydataset,row_dataset)
    }
    
  }
  write.csv(mydataset,"complete_data.csv", row.names = FALSE)

} else {
  filename <- "input/clean_data.csv"
  row_dataset <- read.csv2(filename,header=TRUE)
  colindex <-which(names(row_dataset) %in% col_names)
  row_dataset <-row_dataset[ , (names(row_dataset) %in% col_names)]
  col_names <- colnames(row_dataset) 
  row_dataset[row_dataset==""]<-NA
  row_dataset[row_dataset=="unknown"]<-NA  
  row_dataset <- row_dataset[which(!is.na(row_dataset$nutriscore_score)),]
}

rm(i,files_list,filename,colindex)
```

Pre-processing done!

```{r echo=FALSE, message=FALSE, warning=FALSE}
mydataset <- data.frame(row_dataset)
mydataset[nutrition] <- apply(mydataset[nutrition],2,as.numeric)

errata <- !is.na(mydataset[nutrition])&(mydataset[nutrition]>1000)
mydataset[nutrition][errata] <- mydataset[nutrition][errata]/1000
mydataset[nutrition][is.na(mydataset[nutrition])] <- 0.0
mydataset[nutrition][mydataset[nutrition]>100] <- NA
rm(errata)
mydataset <- mydataset[which(rowMeans(!is.na(mydataset)) > 0.9),]


```


```{r echo=FALSE, message=FALSE, warning=FALSE}
## Take columns with more than 90% not NA 

X <- data.matrix(mydataset[c("nutriscore_score","nova_group",nutrition, "additives_n")])
n <- nrow(X); varnames <- colnames(X)
p <- ncol(X); indnames <- rownames(X)

boxplot(X)

```


Outlier detection and imputation of missing values!
```{r echo=FALSE, message=FALSE, warning=FALSE}
X_nonmiss <-X[which(rowMeans(!is.na(mydataset)) == 1),]
md = mahalanobis(X_nonmiss, center=apply(X_nonmiss, 2, mean), cov=var(X_nonmiss))
plot(density(md))
sort(md)

to_cut <- md[md>quantile(md, 0.975)]
to_cut <- row.names(as.matrix(to_cut))
X_nonoutlier <- X[-which(rownames(X) %in% to_cut),]
par(mfrow=c(1,1))
boxplot(X_nonoutlier)
```
```{r echo=FALSE, message=FALSE, warning=FALSE}
#IMPUTATION OF THE MISSING VALUES#
library("mice")

imp <- mice(X_nonoutlier, m = 1, nnet.MaxNWts = 2000, method="cart")

X <- complete(imp)

summary(X)
rm(imp, row_dataset, X_nonmiss, X_nonoutlier, md)
```

```{r echo=FALSE, message=FALSE, warning=FALSE}
mydataset <- mydataset[-which(rownames(mydataset) %in% to_cut),]
mydataset[c("nutriscore_score","nova_group",nutrition, "additives_n")] <- X
write.csv(mydataset,"final_data.csv", row.names = FALSE)
```






Clustering!
```{r echo=FALSE, message=FALSE, warning=FALSE}
rm(mydataset,X)
library(dplyr)
library (ggplot2)
library(FactoMineR)
library(factoextra)
library("matrixStats")
library("ggplot2")
library("gridExtra")
library("ggpubr")
library("DMwR")
library("plsdepot")
library("ggplot2")
library("ggpubr")
library ("cclust")
library("fpc")

nutrition <- c(
  "fat_100g",
  "carbohydrates_100g",
  "sugars_100g",
  "proteins_100g",
  "salt_100g",
  "fiber_100g"
)

#remove factor and responsive vble
set.seed(1876)
mydataset <- read.csv("final_data.csv")

test.index = sample(1:nrow(mydataset), nrow(mydataset)*0.01)

data.nograde <- mydataset[c("nutriscore_score","nova_group",nutrition, "additives_n")]
data.test = data.nograde[test.index,]
data.train = data.nograde[-test.index,]
```

```{r echo=FALSE, message=FALSE, warning=FALSE}
#PCA con funcion
res.pca <- prcomp(data.test, center = TRUE, scale. = TRUE)
summary(res.pca)

fviz_eig(res.pca)
# Eigenvalues
eig.val <- get_eigenvalue(res.pca)
eigenvalues <- eig.val$eigenvalue
kaiser.rule.lim <- mean(eigenvalues)
sign.comp <- which(eig.val$eigenvalue > kaiser.rule.lim) #we have 3 significant dimentions
print(sign.comp)
## print same plots in previous pca for sing comp analysys
```

```{r echo=FALSE, message=FALSE, warning=FALSE}
### hc clustering

res.ind <- get_pca_ind(res.pca)
Psi <- res.ind$coord[,sign.comp]
d <- dist(Psi, method = "euclidean")
h.clust <- hclust(d, method="ward.D2")
plot(h.clust)

ini = length(h.clust$height)-20
barplot(h.clust$height[ini:length(h.clust$height)],title="20 Larger tree heights")
```


```{r echo=FALSE, message=FALSE, warning=FALSE}
##consolidation operation

library(ggthemes)
ind.clusters = cutree(hc, 5)
table(ind.clusters)

da = list(data=Psi, cluster=ind.clusters)

centroids = aggregate(Psi, list(ind.clusters), mean)

clust.cent <- aggregate(Psi,list(ind.clusters),mean)[,2:4]
Bss <- sum(rowSums(clust.cent^2)*as.numeric(table(ind.clusters)))
Tss <- sum(rowSums(Psi^2))
Ib <- 100*Bss/Tss
print(paste0("Inertia between clusters is ", round(Ib, digits=3), "%"))
```

```{r echo=FALSE, message=FALSE, warning=FALSE}
k.means <- kmeans(Psi,centers=clust.cent)

###catdes

catdes(cbind(as.factor(k.means$cluster), data.test),1)

plot(Psi[,1],Psi[,2],type="n",main="Clustering with consolidation operation")
text(Psi[,1],Psi[,2],col=k5$cluster,cex = 0.6)
abline(h=0,v=0,col="gray")
legend("bottomleft",c("c1","c2","c3","c4", "c5"),pch=20,col=c(1:5))

```


```{r echo=FALSE, message=FALSE, warning=FALSE}
#define number of classes
num.clust <- 5
ind.clusters <- cutree(h.clust, k=num.clust)

table(ind.clusters) #classes and nr of elements for each

da = list(data=Psi, cluster=ind.clusters)
plot <-fviz_cluster(da,ggtheme = theme_minimal())
plot


```


```{r echo=FALSE, message=FALSE, warning=FALSE}
#  5  Compute the Calinski-Harabassz index 
Wss <- sum(k.means$withinss)                        

before_conso_index =  round(calinhara(da$data,da$cluster),digits=2)
before_conso_index
 
  
after_conso_index = round(calinhara(Psi,k.means$cluster),digits=2)
after_conso_index


#CH.3 <- clustIndex(Psi,int.clust, index="calinski")
CH_after= (Bss/Wss)
CH_after

CH_before=Bss/(Bss+Tss)
CH_before
#calculate it with and without kmeans


#the result is improved with calinski-Harabassz


# 6   Using the function catdes interpret and name the obtained clusters
#and represent them in the first factorial display. 
desc <- catdes(as.factor(k.means$cluster),1)
desc$quanti

#  representation of clusters in first factorial plane

kmeans.cent <- k.means$centers
kmeans.cent

first_factorial <- fviz_cluster(k.means, data=Psi, k = num.clust, rect = TRUE, main = "Hclust ward",ggtheme = theme_minimal())
first_factorial




```

```{r}
mydataset = read.csv("final_data.csv",header=TRUE)
```


```{r}

set.seed(1876)
test.index = sample(1:nrow(mydataset), nrow(mydataset)*0.1)

data.nograde = subset(mydataset, select= -nutriscore_grade)

data.test = data.nograde[test.index,]
data.train = data.nograde[-test.index,]
```

```{r}
library(rattle)
tree = rpart(nutriscore_score~., data=data.train, control=rpart.control(cp=0.001, xval=10))

plotcp(tree)
printcp(tree)
```
There's a large drop after split 23

```{r}
as.data.frame(tree$cptable)
```

```{r}
barplot(tree$variable.importance)
```
```{r}
#library(ROCR) # maybe
library(caret)

predictions.train = predict(tree, newdata=data.train)
r2.train = R2(predictions.train, data.train$nutriscore_score)

predictions.test = predict(tree, newdata=data.test)
r2.test = R2(predictions.test, data.test$nutriscore_score)
```

